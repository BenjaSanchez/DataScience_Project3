DT
DT[,m:={tmp<-(x+z);log2(tmp+5)}]
DT
DT[,a:=x>0]
DT
DT[,b:=mean(y+w),by=a]
DT[,{b:=mean(y+w),by=a}]
DT[,b:=mean(y+w),by=a]
DT[,b:=mean(x+w),by=a]
DT
setkey(DT,y)
DT['a']
DT['b']
DT
fileURL2<-'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(fileURL2,destfile='microdata.csv')
microdata<-read.csv('microdata.csv')
View(microdata)
microdata[,VAL==24]
microdata[,microdata$VAL==24]
microdata$VAL==24
sum(microdata$VAL==24,na.rm=TRUE)
fileURL='https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx'
download.file(fileURL,destfile='naturalGas.xlsx')
naturalGas<-read.csv('naturalGas.xlsx')
naturalGas<-read.xlsx('naturalGas.xlsx')
library(xlsx)
naturalGas<-read.xlsx('naturalGas.xlsx')
naturalGas<-read.xlsx('naturalGas.xlsx',sheet=1)
naturalGas<-read.xlsx('naturalGas.xlsx',sheetIndex=1)
naturalGas<-read.xlsx('naturalGas.xlsx',sheetIndex=1,header=TRUE)
7:15
dat<-read.xlsx('naturalGas.xlsx',sheetIndex=1,colIndex=7:15,rowIndex=18:23)
dat<-read.xlsx('naturalGas.xlsx',sheetIndex=1,colIndex=7:15,rowIndex=18:23)
library(xlsx)
dat<-read.xlsx('naturalGas.xlsx',sheetIndex=1,colIndex=7:15,rowIndex=18:23)
dat''
dat
sum(dat$Zip*dat$Ext,na.rm=TRUE)
fileURL<-https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
fileURL<-'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml'
library(XML)
doc<-xmlTreeParse(fileURL,useInternal=TRUE)
doc<-xmlTreeParse(fileURL)
fileURL
doc<-xmlTreeParse(fileURL,useInternal=TRUE)
fileURL<-'http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml'
doc<-xmlTreeParse(fileURL,useInternal=TRUE)
doc
head(doc)
cat(doc)
rootNode<-xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
names(rootNode[[1]])
rootNode[[1]][[1]]
rootNode[[1]][[1]][2]
rootNode[[1]][[1]][[2]]
xpathSApply(rootNode,'//zipcode',xmlValue)
xpathSApply(rootNode,'//zipcode',xmlValue)==21231
sum(xpathSApply(rootNode,'//zipcode',xmlValue)==21231)
fileURL<-'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv'
download.file(fileURL,destfile='microdata2006.csv')
DT<-fread('microdata2006.csv')
library(data.table)
DT<-fread('microdata2006.csv')
View(DT)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15) mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15),mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15),mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15),mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15),mean(DT[DT$SEX==2,]$pwgtp15))
mean(DT[DT$SEX==1,]$pwgtp15),mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT[DT$SEX==1,]$pwgtp15)
mean(DT[DT$SEX==1,]$pwgtp15),mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT[DT$SEX==1,]$pwgtp15) mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT[DT$SEX==1,]$pwgtp15)
mean(DT[DT$SEX==2,]$pwgtp15)
system.time(mean(DT[DT$SEX==1,]$pwgtp15))+system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))+system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))+system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))+system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT$pwgtp15,by=DT$SEX))
mean(DT$pwgtp15,by=DT$SEX)
mean(DT$pwgtp15,by=DT$SEX)
mean(DT$pwgtp15,by=DT$SEX)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
rowMeans(DT)[DT$SEX==1]
rowMeans(DT)[DT$SEX==2]
sapply(split(DT$pwgtp15,DT$SEX),mean)
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
DT[,mean(pwgtp15),by=SEX]
system.time(DT[,mean(pwgtp15),by=SEX])
tapply(DT$pwgtp15,DT$SEX,mean)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
sum(microdata$VAL==24,na.rm=true)
sum(microdata$VAL==24,na.rm=TRUE)
sum(dat$Zip*dat$Ext,na.rm=T)
sum(xpathSApply(rootNode,'//zipcode',xmlValue)==21231)
DT[,mean(pwgtp15),by=SEX]
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(fileURL,destfile='./microdata2006.csv')
microdata2006<-read.csv('microdata2006.csv')
View(microdata2006)
View(microdata)
microdata2006$VAL
sum(microdata2006$VAL==24)
sum(microdata2006$VAL==24,na.rm=true)
sum(microdata2006$VAL==24,na.rm=True)
sum(microdata2006$VAL==24,na.rm = yes)
sum(microdata2006$VAL==24,na.rm = 1)
fileURL2<-'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx'
download.file(fileURL2,destfile='./naturalGas.xlsx')
library(xlsx)
load(rJava)
install.packages("rJava")
load(rJava)
library(xlsx)
library(rJava)
library("rJava", lib.loc="~/R/win-library/3.1")
detach("package:rJava", unload=TRUE)
library(xlsx)
naturalGas<-read.xlsx('naturalGas.xlsx')
install.packages("rJava")
library(xlsx)
library(rJava)
library(rJava)
library(xlsx)
naturalGas<-read.xlsx('naturalGas.xlsx')
dat<-read.xlsx('naturalGas.xlsx',sheetIndex=1,colIndex=7:15,rowIndex=18:23)
dat<-read.xlsx('./naturalGas.xlsx',sheetIndex=1,colIndex=7:15,rowIndex=18:23)
download.file(fileURL2,destfile='./naturalGas.xlsx')
dat<-read.xlsx('./naturalGas.xlsx',sheetIndex=1,colIndex=7:15,rowIndex=18:23)
download.file(fileURL2,destfile='./naturalGas.xlsx',mode='wb')
dat<-read.xlsx('./naturalGas.xlsx',sheetIndex=1,colIndex=7:15,rowIndex=18:23)
View(dat)
sum(dat$Zip*dat$Ext,na.rm=T)
library(XML)
fileURL3<-'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml'
doc<-xmlTreeParse(fileURL3,useInternal=TRUE)
fileURL3<-'htps://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml'
doc<-xmlTreeParse(fileURL3,useInternal=TRUE)
fileURL3<-'http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml'
doc<-xmlTreeParse(fileURL3,useInternal=TRUE)
rootNode<-xmlRoot(doc)
rootNode
names(rootNode)
rootNode[1]
rootNode[[1]]
rootNode[[1]][[1]]
rootNode[[1]][[1]][[1]]
xpathSApply(rootNode,'//zipcode',xmlValue)
sum(xpathSApply(rootNode,'//zipcode',xmlValue)==21231)
fileURL4<-'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv'
download.file(fileURL4,destfile='./microdata.csv')
microdata<-read.csv('/.microdata.csv')
microdata<-read.csv('microdata.csv')
View(microdata)
DT<-read.csv('microdata.csv')
View(DF)
View(DT)
tables()
library(data.table)
tables()
DT<-data.table(DT)
tables()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
tapply(DT$pwgtp15,DT$SEX,mean)
DT[,mean(pwgtp15),by=SEX]
mean(DT$pwgtp15,by=DT$SEX)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
sapply(split(DT$pwgtp15,DT$SEX),mean)
install.packages('RMySQL')
library(RMySQL)
ucscDB <- dbConnect(MySQL(),user='genome',host='genome-mysql.cse.ucsc.edu')
result <- dbGetQuery(ucscDB,'show databases;');dbDisconnect(ucscDB);
result
hg19 <- dbConnect(MySQL(),user='genome',db='hg19',host='genome-mysql.cse.ucsc.edu')
allTables<-dbListTables(hg19)
allTables[1:5]
dbListFields(hg19,'affyU133Plus2')
dbGetQuery(hg19,'select count(*) from affyU133Plus2')
affyData<-dbReadTable(hg19,'affyU133Plus2')
warnings()
head(affyData)
query<-dbSendQuery(hg19,'select * from affyU133Plus2 where misMatches between 1 and 3')
affyMis <- fetch(query);quantile(affyMiss$misMatches)
affyMis <- fetch(query);quantile(affyMis$misMatches)
affyMisSmall<-fetch(query,n=10);dbClearResult(query);
dim(affyMisSmall)
affyMisSmall
dbDisconnect(hg19)
source('http://bioconductor.org/biocLite.R')
biocLite('rhdf5')
biocLite('rhdf5')
library(rhdf5)
library(rhdf5)
created = h5createFile('example.h5')
created
created = h5createGroup('example.h5','foo')
created = h5createGroup('example.h5','baa')
created = h5createGroup('example.h5','foo/foobaa')
h5ls('example.h5')
A = matrix(1:10,nr=5,nc=2)
h5write(A,'example.h5','foo/A')
B=array(seq(0.1,2.0,by=0.1),dim=c(5,2,2))
attr(B,'scale')<-'liter'
h5write(B,'example.h5','foo/foobaa/B')
h5ls('example.h5')
df = data.frame(1L:5L,seq(0,1,length.out=5),c('ab','cde',''))
df = data.frame(1L:5L,seq(0,1,length.out=5),c('ab','cde','fghi','a','s'),stringAsFactors=FALSE)
h5write(df,'example.h5','df')
h5ls('example.h5')
readA=h5read('example.h5','foo/A')
readA
h5write(c(12,13,14),'example.h5','foo/A',index=list(1:3,1))
readA=h5read('example.h5','foo/A')
readA
readA=h5read('example.h5','foo/A',index=list(1:3,1))
readA
con = url('https://scholar.google.se/citations?user=1Wvwvv0AAAAJ&hl=en')
htmlCode = readLines(con)
close(con)
htmlCode
library(XML)
html<-htmlTreeParse('https://scholar.google.se/citations?user=1Wvwvv0AAAAJ&hl=en',useInternalNodes=T)
html<-htmlTreeParse('http://scholar.google.se/citations?user=1Wvwvv0AAAAJ&hl=en',useInternalNodes=T)
xpathSAPPLY(HTML,'//title',xmlValue)
xpathSApply(html,'//title',xmlValue)
xpathSApply(html,'//td[@id='col-cytedby']',xmlValue)
xpathSApply(html,'//td[@id=\'col-cytedby\']',xmlValue)
xpathSApply(html,"//td[@id='col-cytedby']",xmlValue)
xpathSApply(html,"//td[@id='col-citedby']",xmlValue)
library(httr);html2=GET('https://scholar.google.se/citations?user=1Wvwvv0AAAAJ&hl=en')
content2=content(html2,as='text')
parsedHtml=htmlParse(content2,asText=TRUE)
xpathSApply(parsedHtml,'//title',xmlValue)
xpathSApply(html,"//td[@id='col-citedby']",xmlValue)
pg2=GET('http://httpbin.org/basic-auth/user/passwd')
pg2
pg2=GET('http://httpbin.org/basic-auth/user/passwd',authenticate('user','passwd'))
pg2
names(pg2)
google=handle('http://google.com')
pg1=GET(handle=google,path='/')
pg1
library(httr)
oauth_endpoints('github')
myapp<-oauth_app('github',,'ac3f42ed1349988ca47e')
myapp<-oauth_app('github','ac3f42ed1349988ca47e')
myapp<-oauth_app('github',key = 'ac3f42ed1349988ca47e',secret = 'd4e95c350fcefeffe2f04d622137495d143464ea')
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
sig<-sign_oauth1.0(myapp,token='a2bea0cbec12528d2010d04df312eb5737adc569 ')
gtoken <- config(token = github_token)
req <- GET("https://github.com/jtleek/datasharing", gtoken)
print req
content(req)
library(jsonlite)
names(req)
names(req$date)
req$date
names(req$content)
req$content
req1=content(req)
req2=jsonlite::fromJSON(toJSON(req1))
req2=toJSON(req1)
req1
content(req)
req1
req1<-content(req)
req1
req2<-toJSON(req1)
req
names(req)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
content(req)
oauth_endpoints("github")
myapp<-oauth_app('github',key = 'ac3f42ed1349988ca47e',secret = 'd4e95c350fcefeffe2f04d622137495d143464ea')
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
oauth_endpoints("github")
myapp<-oauth_app('github',key = 'ac3f42ed1349988ca47e',secret = 'd4e95c350fcefeffe2f04d622137495d143464ea')
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
library(httpuv)
library(httr)
myapp<-oauth_app('github',key = 'ac3f42ed1349988ca47e',secret = 'd4e95c350fcefeffe2f04d622137495d143464ea')
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
req
library(httr)
library(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("github",key='ac3f42ed1349988ca47e',secret='d4e95c350fcefeffe2f04d622137495d143464ea')
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
content(req)
require(httr)
require(httpuv)
myapp <- oauth_app("github",key='ac3f42ed1349988ca47e',secret='d4e95c350fcefeffe2f04d622137495d143464ea')
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
req1<-content(req)
library(jsonlite)
req2<-toJSON(req)
req2<-toJSON(req1)
req3<-jsonlite::fromJSON(req2)
req3
req$content
content(req)
library(httr)
library(httpuv)
require(httr)
require(httpuv)
myapp <- oauth_app("github",key="adc2d4583f7568b43820",secret = "33ea1343d9179a7ce9ce07b1d872ffcaf65e7cc6")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
content(req)
req1<-content(req)
req1
library(jsonlite)
req2<-jsonlite::fromJSON(toJSON(req1))
req2
names(req2)
req2$datasharing
req2$id
names(req2)
req2$name
req2
names(req2)
req2$created_at
req2$created_at[3]
req2$created_at['datasharing']
req2$created_at[req2$name='datasharing']
req2$created_at[req2$name=='datasharing']
install.packages(sqldf)
install.packages('sqldf')
library(sqldf )
library(sqldf)
require(sqldf)
url<-'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv'
download.file(url,destfile='survey.csv')
acs<-read.table(survey.csv)
acs<-read.table('survey.csv')
View(acs)
acs<-read.csv('survey.csv')
View(acs)
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select * from acs where AGEP < 50")
sqldf("select pwgtp1 from acs")
sqldf("select * from acs")
sqldf("select pwgtp1 from acs where AGEP < 50")
unique(acs$AGEP)
sqldf("select unique AGEP from acs")
sqldf("select distinct AGEP from acs")
sqldf("select unique * from acs")
sqldf("select distinct pwgtp1 from acs")
?unique
html<-url('http://biostat.jhsph.edu/~jleek/contact.html')
library(XML)
url<-'http://biostat.jhsph.edu/~jleek/contact.html '
url<-'http://biostat.jhsph.edu/~jleek/contact.html'
html<-htmlTreeParse(url,useInternalNodes=T)
html
xpatSApply(html)
xpathSApply(html)
con<-url('http://biostat.jhsph.edu/~jleek/contact.html')
htmlCode<-readLines(con)
close(con)
htmlCode
htmlCode[10]
htmlCode[10,20]
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
url<-'https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for'
download.file(url,destfile='data_quizz2.for')
data<-read.table('data_quizz2.for',sep='\t')
View(data)
data<-read.table('data_quizz2.for',sep='\t',header=TRUE)
View(data)
data<-read.table('data_quizz2.for',sep='     ',header=TRUE)
data<-read.table('data_quizz2.for',sep=' ',header=TRUE)
data<-read.csv('data_quizz2.for')
View(data)
data<-read.csv('data_quizz2.for',sep='\t')
View(data)
data<-read.fwf('data_quizz2.for',widths=c(9,4,4,4,4,4,4,4,4),header=TRUE)
data<-read.fwf('data_quizz2.for',widths=c(9,4,4,4,4,4,4,4,4),header=TRUE,sep='\t')
data<-read.fwf('data_quizz2.for',widths=c(9,4,4,4,4,4,4,4,4),header=TRUE,sep=' ')
data<-read.fwf('data_quizz2.for',widths=c(9,4,4,4,4,4,4,4,4),skip=3,sep=' ')
data<-read.fwf('data_quizz2.for',widths=c(9,4,4,4,4,4,4,4,4),skip=3)
View(data)
data<-read.fwf('data_quizz2.for',widths=c(1,9,5,4,4,5,4,4,5,4,4,5,4,4),skip=3)
View(data)
sum(data$V7)
data$V7
?sum
sum(data[,7])
sum(data[2:,7])
sum(data[2:end,7])
data<-read.fwf('data_quizz2.for',widths=c(1,9,5,4,4,5,4,4,5,4,4,5,4,4),skip=4)
View(data)
sum(data[,7])
set.seed(13435)
X<-data.frame('car1'=sample(1:5),'var2'=sample(6:10),'ar3'=sample(11:15))
X
X<-data.frame('var1'=sample(1:5),'var2'=sample(6:10),'ar3'=sample(11:15))
X
X<-data.frame('var1'=sample(1:5),'var2'=sample(6:10),'var3'=sample(11:15))
X
set.seed(13435)
X<-data.frame('var1'=sample(1:5),'var2'=sample(6:10),'var3'=sample(11:15))
X
X<-X[sample(1:5),];X$var2[c(1,3)]=NA
X
X[,1]
X[,'var1']
X[1:2,'var2']
X[(X$var1<=3 & X$var3>11),]
X[(X$var1<=3 | X$var3>11),]
X[which(X$var2>8),]
sort(X$var1)
sort(X$var1,decreasing=TRUE)
sort(X$var2,na.last=TRUE,decreasing=TRUE)
sort(X$var2,na.rm=TRUE,decreasing=TRUE)
X[order(X$var1),]
order(X$var1)
order(X$var1,X$var3)
X[order(X$var1,X$var3),]
library(plyr)
arrange(X,var1)
arrange(X,desc(var1)
)
arrange(X,desc(var1))
X$var4 <-rnorm(5)
X
Y<-cbind(X,rnorm(5))
Y
Y<-rbind(X,rnorm(5))
Y
Y<-rbind(rnorm(4),X)
Y
url<-'https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD'
download.file(url,destfile='restaurants.csv')
restData<-read.csv('restaurants.csv')
View(restData)
head(restData,n=3)
tail(restData,n=3)
summary(restData)
str(restData)
quantile(restData$councilDistrict,na.rm=TRUE)
quantile(restData$councilDistrict,probs=c(0.5,0.75,0.9))
table(restData$zipCode,useNA='ifany')
table(restData$councilDistrict,restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$councilDistrict>0)
colSums(is.na(restData))
all(colSums(is.na(restData)))
all(colSums(is.na(restData))==0)
table(restData$zipCode %in% c('21212','21213'))
restData[restData$zipCode %in% c('21212','21213'),]
head(restData[restData$zipCode %in% c('21212','21213'),])
summary(restData)
summary(restData)
data(UCBAdmissions)
DF=as.data.frame(UCBAdmissions)
DF
summary(DF)
xt<-xtabs(Freq ~ Gender + Admit,data=DF)
xt
View(DF)
s1<-seq(1,10,by=2)
s1
s2<-seq(1,10,length=3)
s2
x<-c(1,3,8,25,100)
seq(along=x)
restData$nearMe <-restData$neighborhood %in% c('Roland Park','Homeland')
View(restData)
table(restData$nearMe)
restData$zipWrong = ifelse(restData$zipCode < 0,TRUE,FALSE)
summary(restData)
restData$zipGroups = cut(restData$zipCode,breaks=quantile(restData$zipCode))
summary(restData)
table(restData$zipGroups,restData$zipCode)
library(Hmisc)
restDat$zipGroups = cut2(restData$zipCode,g=4)
restData$zipGroups = cut2(restData$zipCode,g=4)
table(restData$zipGroups)
summary(restData)
restData$zcf<-factor(restData$zipCode)
head(restData$zcf)
yesno<-sample(c('yes','no'),size=10,replace=TRUE)
yesnofac=factor(yesno,levels=c('yes','no'))
yesno
yesnofac
relevel(yesnofac,ref='yes')
as.numeric(yesnofac)
summary(restData)
setwd("~/Dropbox/PhD/Cursos/Coursera/3. Getting & Cleaning Data/Project")
